{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "827ffe8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b04e8beb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tech</td>\n",
       "      <td>tv future in the hands of viewers with home th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>business</td>\n",
       "      <td>worldcom boss  left books alone  former worldc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sport</td>\n",
       "      <td>tigers wary of farrell  gamble  leicester say ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sport</td>\n",
       "      <td>yeading face newcastle in fa cup premiership s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>entertainment</td>\n",
       "      <td>ocean s twelve raids box office ocean s twelve...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        category                                               text\n",
       "0           tech  tv future in the hands of viewers with home th...\n",
       "1       business  worldcom boss  left books alone  former worldc...\n",
       "2          sport  tigers wary of farrell  gamble  leicester say ...\n",
       "3          sport  yeading face newcastle in fa cup premiership s...\n",
       "4  entertainment  ocean s twelve raids box office ocean s twelve..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datapath = r\"C:\\Users\\drang\\Downloads\\toxic\\data\\bbc-text.csv\\bbc-text.csv\"\n",
    "df = pd.read_csv(datapath)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "96db264a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='category'>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.groupby(\"category\").size().plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4f155af4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 101,  146, 1209, 2824, 1567, 2052, 3568,  102,    0,    0]])\n",
      "tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n",
      "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 0, 0]])\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-cased')\n",
    "\n",
    "example_text = 'I will watch love today tonight'\n",
    "bert_input = tokenizer(example_text, padding='max_length', max_length = 10, \n",
    "                       truncation=True, return_tensors=\"pt\")\n",
    "\n",
    "#pt for pytorch, 10 for max visual\n",
    "print(bert_input['input_ids'])\n",
    "print(bert_input['token_type_ids'])\n",
    "print(bert_input['attention_mask'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4dd75c54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['input_ids', 'token_type_ids', 'attention_mask']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(bert_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0d642137",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[CLS] I will watch love today tonight [SEP] [PAD] [PAD]'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "egtxt = tokenizer.decode(bert_input.input_ids[0])\n",
    "egtxt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "18ea0843",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from transformers import BertTokenizer\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-cased')\n",
    "labels = {'business':0,\n",
    "          'entertainment':1,\n",
    "          'sport':2,\n",
    "          'tech':3,\n",
    "          'politics':4\n",
    "          }\n",
    "\n",
    "class Dataset(torch.utils.data.Dataset):\n",
    "\n",
    "    def __init__(self, df):\n",
    "\n",
    "        self.labels = [labels[label] for label in df['category']]\n",
    "        self.texts = [tokenizer(text, \n",
    "                               padding='max_length', max_length = 512, truncation=True,\n",
    "                                return_tensors=\"pt\") for text in df['text']]\n",
    "\n",
    "    def classes(self):\n",
    "        return self.labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def get_batch_labels(self, idx):\n",
    "        # Fetch a batch of labels\n",
    "        return np.array(self.labels[idx])\n",
    "\n",
    "    def get_batch_texts(self, idx):\n",
    "        # Fetch a batch of inputs\n",
    "        return self.texts[idx]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        batch_texts = self.get_batch_texts(idx)\n",
    "        batch_y = self.get_batch_labels(idx)\n",
    "\n",
    "        return batch_texts, batch_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b9741849",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1780 222 223\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.random.seed(112)\n",
    "df_train, df_val, df_test = np.split(df.sample(frac=1, random_state=42), \n",
    "                                     [int(.8*len(df)), int(.9*len(df))])\n",
    "# For example, [2, 3] would, for axis=0, result in ary[:2]'ary[2:3],ary[3:]\n",
    "print(len(df_train),len(df_val), len(df_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "de9eab70",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "from transformers import BertModel\n",
    "\n",
    "class BertClassifier(nn.Module):\n",
    "\n",
    "    def __init__(self, dropout=0.5):\n",
    "\n",
    "        super(BertClassifier, self).__init__()\n",
    "\n",
    "        self.bert = BertModel.from_pretrained('bert-base-cased')\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.linear = nn.Linear(768, 5)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, input_id, mask):\n",
    "\n",
    "        _, pooled_output = self.bert(input_ids= input_id, attention_mask=mask,return_dict=False)\n",
    "        dropout_output = self.dropout(pooled_output)\n",
    "        linear_output = self.linear(dropout_output)\n",
    "        final_layer = self.relu(linear_output)\n",
    "\n",
    "        return final_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "214389c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 890/890 [03:15<00:00,  4.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 1 | Train Loss:  0.772                 | Train Accuracy:  0.313                 | Val Loss:  0.655                 | Val Accuracy:  0.559\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 890/890 [03:15<00:00,  4.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 2 | Train Loss:  0.424                 | Train Accuracy:  0.807                 | Val Loss:  0.232                 | Val Accuracy:  0.977\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 890/890 [03:15<00:00,  4.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 3 | Train Loss:  0.160                 | Train Accuracy:  0.978                 | Val Loss:  0.104                 | Val Accuracy:  0.982\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 890/890 [03:15<00:00,  4.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 4 | Train Loss:  0.079                 | Train Accuracy:  0.989                 | Val Loss:  0.066                 | Val Accuracy:  0.995\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 890/890 [03:15<00:00,  4.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 5 | Train Loss:  0.046                 | Train Accuracy:  0.993                 | Val Loss:  0.038                 | Val Accuracy:  0.995\n"
     ]
    }
   ],
   "source": [
    "from torch.optim import Adam\n",
    "from tqdm import tqdm\n",
    "\n",
    "def train(model, train_data, val_data, learning_rate, epochs):\n",
    "\n",
    "    train, val = Dataset(train_data), Dataset(val_data)\n",
    "\n",
    "    train_dataloader = torch.utils.data.DataLoader(train, batch_size=2, shuffle=True)\n",
    "    val_dataloader = torch.utils.data.DataLoader(val, batch_size=2)\n",
    "\n",
    "    use_cuda = torch.cuda.is_available()\n",
    "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = Adam(model.parameters(), lr= learning_rate)\n",
    "\n",
    "    if use_cuda:\n",
    "\n",
    "            model = model.cuda()\n",
    "            criterion = criterion.cuda()\n",
    "\n",
    "    for epoch_num in range(epochs):\n",
    "\n",
    "            total_acc_train = 0\n",
    "            total_loss_train = 0\n",
    "\n",
    "            for train_input, train_label in tqdm(train_dataloader):\n",
    "\n",
    "                train_label = train_label.to(device)\n",
    "                mask = train_input['attention_mask'].to(device)\n",
    "                input_id = train_input['input_ids'].squeeze(1).to(device)\n",
    "\n",
    "                output = model(input_id, mask)\n",
    "                \n",
    "                batch_loss = criterion(output, train_label.long())\n",
    "                total_loss_train += batch_loss.item()\n",
    "                \n",
    "                acc = (output.argmax(dim=1) == train_label).sum().item()\n",
    "                total_acc_train += acc\n",
    "\n",
    "                model.zero_grad()\n",
    "                batch_loss.backward()\n",
    "                optimizer.step()\n",
    "            \n",
    "            total_acc_val = 0\n",
    "            total_loss_val = 0\n",
    "\n",
    "            with torch.no_grad():\n",
    "\n",
    "                for val_input, val_label in val_dataloader:\n",
    "\n",
    "                    val_label = val_label.to(device)\n",
    "                    mask = val_input['attention_mask'].to(device)\n",
    "                    input_id = val_input['input_ids'].squeeze(1).to(device)\n",
    "\n",
    "                    output = model(input_id, mask)\n",
    "\n",
    "                    batch_loss = criterion(output, val_label.long())\n",
    "                    total_loss_val += batch_loss.item()\n",
    "                    \n",
    "                    acc = (output.argmax(dim=1) == val_label).sum().item()\n",
    "                    total_acc_val += acc\n",
    "            \n",
    "            print(\n",
    "                f'Epochs: {epoch_num + 1} | Train Loss: {total_loss_train / len(train_data): .3f} \\\n",
    "                | Train Accuracy: {total_acc_train / len(train_data): .3f} \\\n",
    "                | Val Loss: {total_loss_val / len(val_data): .3f} \\\n",
    "                | Val Accuracy: {total_acc_val / len(val_data): .3f}')\n",
    "                  \n",
    "EPOCHS = 5\n",
    "model = BertClassifier()\n",
    "LR = 1e-6\n",
    "              \n",
    "train(model, df_train, df_val, LR, EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "20958655",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"BBC CLASSIFY USING BERT1.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "05bdd3e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertClassifier(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(28996, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       "  (linear): Linear(in_features=768, out_features=5, bias=True)\n",
       "  (relu): ReLU()\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = BertClassifier()\n",
    "model.load_state_dict(torch.load(\"BBC CLASSIFY USING BERT1.pt\"))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47903c1b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "99953368",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, val = Dataset(df_train), Dataset(df_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "8f53319f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(1)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.__getitem__(2)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "9dd57883",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First item: 1\n",
      "Second item: 2\n",
      "Third item: 3\n"
     ]
    }
   ],
   "source": [
    "class A:\n",
    "    def __init__(self, item):\n",
    "        self.item = item\n",
    "    def __getitem__(self, index):\n",
    "        return self.item[index]\n",
    "a = A([1, 2, 3])\n",
    "print(f\"First item: {a[0]}\")\n",
    "print(f\"Second item: {a[1]}\")\n",
    "print(f\"Third item: {a[2]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "a1d727d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy:  0.996\n"
     ]
    }
   ],
   "source": [
    "def evaluate(model, test_data):\n",
    "\n",
    "    test = Dataset(test_data)\n",
    "\n",
    "    test_dataloader = torch.utils.data.DataLoader(test, batch_size=2)\n",
    "\n",
    "    use_cuda = torch.cuda.is_available()\n",
    "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "\n",
    "    if use_cuda:\n",
    "\n",
    "        model = model.cuda()\n",
    "\n",
    "    total_acc_test = 0\n",
    "    with torch.no_grad():\n",
    "\n",
    "        for test_input, test_label in test_dataloader:\n",
    "\n",
    "              test_label = test_label.to(device)\n",
    "              mask = test_input['attention_mask'].to(device)\n",
    "              input_id = test_input['input_ids'].squeeze(1).to(device)\n",
    "\n",
    "              output = model(input_id, mask)\n",
    "\n",
    "              acc = (output.argmax(dim=1) == test_label).sum().item()\n",
    "              total_acc_test += acc\n",
    "    \n",
    "    print(f'Test Accuracy: {total_acc_test / len(test_data): .3f}')\n",
    "    \n",
    "evaluate(model, df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "07e83364",
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = df_test[\"text\"][8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "27c5c4f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "texty = [tokenizer(ss, padding='max_length', max_length = 512, truncation=True,\n",
    "                                return_tensors=\"pt\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e12bd3dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  101,   192,  2723,  9615,  1320,  4218,  1106,  1339,  5048,  1394,\n",
       "         16854,  4035,  1403,  1931,  3495,   179,  1320,  3382,   192,  2723,\n",
       "          9615,  1320,  1209,  1294,  1117,  1263,   118, 21520,  1862,  1121,\n",
       "          3773,  1222,  5048,  1394, 16854,  1113,  2068,  2149,  6194,   119,\n",
       "           192,  2723,  9615,  1320,  1150,  1144,  1136,  1307,  1290, 25359,\n",
       "          1117, 16516,  2093,  1643,  1113,  1542,   184,  5822, 21367,  1197,\n",
       "          1261,  1226,  1107,  1554,   118,  3232,  2013,  1114,  1207, 26487,\n",
       "           175,  1348,  7235,  1116,  1113, 26055,  3965,  6194,   119,  1105,\n",
       "          1103,  1512,   118,  1214,   118,  1385,  4689,   118,  1544,  1209,\n",
       "          1838,  2068,  2149,  6194,   188,  1119,  2042,  6378,  4355,  1801,\n",
       "          1120,   182,  2149,  6447,  2427,  1113,  1103,  6757,   119,  1133,\n",
       "          1207, 26487,  1900,  1104,  4896,   187, 12809,  1105, 11899,  1163,\n",
       "           131,  1119,   188,  2503,  1105,  1195,  2810,  1106,  1243,  1140,\n",
       "          1154,  1103,  1342,  1120,  1199,  2016,   119,  1103,  1512,   118,\n",
       "          1214,   118,  1385,  4007,  4035,  1403,  1931,   188,  8929,  1835,\n",
       "          1116,  1170,   170,  9705,  1611, 26465,  1158,  1103,  5871, 14494,\n",
       "         18778,  1161,  1107,  1117,  3105,  1268,  1981,  1222, 21718, 27510,\n",
       "          2316,   119,  1119,  1108,  2886,  2125,  1112,  4035,  1403,  1931,\n",
       "          3495,  1118,  1554,   118,  1171,   179,  2225,  1320, 16763,  2142,\n",
       "           119,  4688,   188, 22572,  1813,  7174, 16358, 26229,  1261,  1166,\n",
       "          1103,  1295,  1275,  2969,  1107,  1103,  1835,  1116,  1222,  1169,\n",
       "          7971,  1588,   170,  2087, 15353,  1105, 12686, 16468,  4567,   119,\n",
       "           192,  2723,  9615,  1320,   188,  1214,  1144,  1151, 22312,  1118,\n",
       "          3773,  1112,  1117,  6484,  2463,  1723,  2022,  1808,  1113,  1103,\n",
       "          1334, 10443,  1114,   170,  2342,  3773,  8505,  1107,  1103,  1362,\n",
       "          4355,  1509,   119,   102,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texty[0]['input_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ebf74993",
   "metadata": {},
   "outputs": [],
   "source": [
    "mo = model(texty[0][\"input_ids\"], texty[0][\"attention_mask\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "65e75e0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'sport'"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(mo.argmax(dim=1))\n",
    "list(labels.keys())[mo.argmax(dim=1).item()] #access dict key using values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "839a15f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sport'"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(labels.keys())[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4a28787",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
